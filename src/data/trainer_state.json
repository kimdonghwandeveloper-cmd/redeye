{
  "best_global_step": 8196,
  "best_metric": 0.5785407725321888,
  "best_model_checkpoint": "./redeye-detection-model\\checkpoint-8196",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8196,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.036603221083455345,
      "grad_norm": 8.034029006958008,
      "learning_rate": 1.9758418740849198e-05,
      "loss": 0.7024983215332031,
      "step": 100
    },
    {
      "epoch": 0.07320644216691069,
      "grad_norm": 1.9694745540618896,
      "learning_rate": 1.9514397266959495e-05,
      "loss": 0.6926325988769532,
      "step": 200
    },
    {
      "epoch": 0.10980966325036604,
      "grad_norm": 3.025233507156372,
      "learning_rate": 1.9270375793069792e-05,
      "loss": 0.6932711029052734,
      "step": 300
    },
    {
      "epoch": 0.14641288433382138,
      "grad_norm": 4.814542293548584,
      "learning_rate": 1.902635431918009e-05,
      "loss": 0.6918826293945313,
      "step": 400
    },
    {
      "epoch": 0.18301610541727673,
      "grad_norm": 3.754218816757202,
      "learning_rate": 1.8782332845290386e-05,
      "loss": 0.6762914276123047,
      "step": 500
    },
    {
      "epoch": 0.21961932650073207,
      "grad_norm": 3.651601791381836,
      "learning_rate": 1.8538311371400686e-05,
      "loss": 0.6426480865478515,
      "step": 600
    },
    {
      "epoch": 0.2562225475841874,
      "grad_norm": 5.388775825500488,
      "learning_rate": 1.8294289897510983e-05,
      "loss": 0.6414913940429687,
      "step": 700
    },
    {
      "epoch": 0.29282576866764276,
      "grad_norm": 2.1959383487701416,
      "learning_rate": 1.805026842362128e-05,
      "loss": 0.6619648742675781,
      "step": 800
    },
    {
      "epoch": 0.3294289897510981,
      "grad_norm": 3.8399667739868164,
      "learning_rate": 1.7806246949731577e-05,
      "loss": 0.6328139114379883,
      "step": 900
    },
    {
      "epoch": 0.36603221083455345,
      "grad_norm": 4.823591232299805,
      "learning_rate": 1.7562225475841877e-05,
      "loss": 0.6507585144042969,
      "step": 1000
    },
    {
      "epoch": 0.40263543191800877,
      "grad_norm": 6.871438026428223,
      "learning_rate": 1.731820400195217e-05,
      "loss": 0.628613395690918,
      "step": 1100
    },
    {
      "epoch": 0.43923865300146414,
      "grad_norm": 2.2302119731903076,
      "learning_rate": 1.707418252806247e-05,
      "loss": 0.6407680511474609,
      "step": 1200
    },
    {
      "epoch": 0.47584187408491946,
      "grad_norm": 2.7894644737243652,
      "learning_rate": 1.6830161054172768e-05,
      "loss": 0.6486809539794922,
      "step": 1300
    },
    {
      "epoch": 0.5124450951683748,
      "grad_norm": 3.511720895767212,
      "learning_rate": 1.658613958028307e-05,
      "loss": 0.6400969696044921,
      "step": 1400
    },
    {
      "epoch": 0.5490483162518301,
      "grad_norm": 5.106034278869629,
      "learning_rate": 1.6342118106393362e-05,
      "loss": 0.647615966796875,
      "step": 1500
    },
    {
      "epoch": 0.5856515373352855,
      "grad_norm": 7.510664463043213,
      "learning_rate": 1.6098096632503662e-05,
      "loss": 0.6421768951416016,
      "step": 1600
    },
    {
      "epoch": 0.6222547584187409,
      "grad_norm": 8.06386661529541,
      "learning_rate": 1.585407515861396e-05,
      "loss": 0.6394528579711914,
      "step": 1700
    },
    {
      "epoch": 0.6588579795021962,
      "grad_norm": 3.1513073444366455,
      "learning_rate": 1.5610053684724256e-05,
      "loss": 0.6370520401000976,
      "step": 1800
    },
    {
      "epoch": 0.6954612005856515,
      "grad_norm": 2.2377076148986816,
      "learning_rate": 1.5366032210834553e-05,
      "loss": 0.6428330230712891,
      "step": 1900
    },
    {
      "epoch": 0.7320644216691069,
      "grad_norm": 5.142160415649414,
      "learning_rate": 1.5122010736944852e-05,
      "loss": 0.6242892074584961,
      "step": 2000
    },
    {
      "epoch": 0.7686676427525623,
      "grad_norm": 2.361229419708252,
      "learning_rate": 1.487798926305515e-05,
      "loss": 0.6332236480712891,
      "step": 2100
    },
    {
      "epoch": 0.8052708638360175,
      "grad_norm": 4.544222831726074,
      "learning_rate": 1.463396778916545e-05,
      "loss": 0.6360000610351563,
      "step": 2200
    },
    {
      "epoch": 0.8418740849194729,
      "grad_norm": 5.321798324584961,
      "learning_rate": 1.4389946315275744e-05,
      "loss": 0.6285932159423828,
      "step": 2300
    },
    {
      "epoch": 0.8784773060029283,
      "grad_norm": 18.337480545043945,
      "learning_rate": 1.4145924841386043e-05,
      "loss": 0.6342880249023437,
      "step": 2400
    },
    {
      "epoch": 0.9150805270863837,
      "grad_norm": 5.3968119621276855,
      "learning_rate": 1.3901903367496342e-05,
      "loss": 0.6344131851196289,
      "step": 2500
    },
    {
      "epoch": 0.9516837481698389,
      "grad_norm": 8.24504566192627,
      "learning_rate": 1.3657881893606639e-05,
      "loss": 0.6521163177490235,
      "step": 2600
    },
    {
      "epoch": 0.9882869692532943,
      "grad_norm": 9.715275764465332,
      "learning_rate": 1.3413860419716936e-05,
      "loss": 0.6179052352905273,
      "step": 2700
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6196925329428989,
      "eval_f1": 0.4551651809124279,
      "eval_loss": 0.6235371828079224,
      "eval_runtime": 113.2823,
      "eval_samples_per_second": 24.117,
      "eval_steps_per_second": 3.019,
      "step": 2732
    },
    {
      "epoch": 1.0248901903367496,
      "grad_norm": 12.310152053833008,
      "learning_rate": 1.3169838945827234e-05,
      "loss": 0.6011156463623046,
      "step": 2800
    },
    {
      "epoch": 1.061493411420205,
      "grad_norm": 6.037765979766846,
      "learning_rate": 1.2925817471937531e-05,
      "loss": 0.619439697265625,
      "step": 2900
    },
    {
      "epoch": 1.0980966325036603,
      "grad_norm": 15.306239128112793,
      "learning_rate": 1.268179599804783e-05,
      "loss": 0.5884853363037109,
      "step": 3000
    },
    {
      "epoch": 1.1346998535871156,
      "grad_norm": 6.904565334320068,
      "learning_rate": 1.2437774524158127e-05,
      "loss": 0.6058536529541015,
      "step": 3100
    },
    {
      "epoch": 1.171303074670571,
      "grad_norm": 5.1055521965026855,
      "learning_rate": 1.2193753050268424e-05,
      "loss": 0.6050809860229492,
      "step": 3200
    },
    {
      "epoch": 1.2079062957540263,
      "grad_norm": 14.172545433044434,
      "learning_rate": 1.1949731576378722e-05,
      "loss": 0.593702278137207,
      "step": 3300
    },
    {
      "epoch": 1.2445095168374818,
      "grad_norm": 4.510225772857666,
      "learning_rate": 1.1705710102489021e-05,
      "loss": 0.6036615371704102,
      "step": 3400
    },
    {
      "epoch": 1.281112737920937,
      "grad_norm": 7.528180122375488,
      "learning_rate": 1.1461688628599316e-05,
      "loss": 0.5758056259155273,
      "step": 3500
    },
    {
      "epoch": 1.3177159590043923,
      "grad_norm": 12.26940631866455,
      "learning_rate": 1.1217667154709615e-05,
      "loss": 0.5892192459106446,
      "step": 3600
    },
    {
      "epoch": 1.3543191800878478,
      "grad_norm": 7.482214450836182,
      "learning_rate": 1.0973645680819913e-05,
      "loss": 0.5885848236083985,
      "step": 3700
    },
    {
      "epoch": 1.390922401171303,
      "grad_norm": 6.519410133361816,
      "learning_rate": 1.0729624206930212e-05,
      "loss": 0.5936994171142578,
      "step": 3800
    },
    {
      "epoch": 1.4275256222547585,
      "grad_norm": 10.653759002685547,
      "learning_rate": 1.0485602733040507e-05,
      "loss": 0.6035221481323242,
      "step": 3900
    },
    {
      "epoch": 1.4641288433382138,
      "grad_norm": 6.327960968017578,
      "learning_rate": 1.0241581259150806e-05,
      "loss": 0.5811106491088868,
      "step": 4000
    },
    {
      "epoch": 1.500732064421669,
      "grad_norm": 8.187744140625,
      "learning_rate": 9.997559785261105e-06,
      "loss": 0.6174080657958985,
      "step": 4100
    },
    {
      "epoch": 1.5373352855051245,
      "grad_norm": 11.480009078979492,
      "learning_rate": 9.753538311371402e-06,
      "loss": 0.6022089385986328,
      "step": 4200
    },
    {
      "epoch": 1.5739385065885798,
      "grad_norm": 11.77955150604248,
      "learning_rate": 9.509516837481698e-06,
      "loss": 0.5852986526489258,
      "step": 4300
    },
    {
      "epoch": 1.610541727672035,
      "grad_norm": 8.294855117797852,
      "learning_rate": 9.265495363591997e-06,
      "loss": 0.5748090362548828,
      "step": 4400
    },
    {
      "epoch": 1.6471449487554906,
      "grad_norm": 6.6005730628967285,
      "learning_rate": 9.021473889702294e-06,
      "loss": 0.5846086883544922,
      "step": 4500
    },
    {
      "epoch": 1.6837481698389458,
      "grad_norm": 6.717447757720947,
      "learning_rate": 8.777452415812591e-06,
      "loss": 0.6150854110717774,
      "step": 4600
    },
    {
      "epoch": 1.720351390922401,
      "grad_norm": 7.6146321296691895,
      "learning_rate": 8.53343094192289e-06,
      "loss": 0.6268793869018555,
      "step": 4700
    },
    {
      "epoch": 1.7569546120058566,
      "grad_norm": 8.946664810180664,
      "learning_rate": 8.289409468033187e-06,
      "loss": 0.5886001205444336,
      "step": 4800
    },
    {
      "epoch": 1.7935578330893118,
      "grad_norm": 4.2510271072387695,
      "learning_rate": 8.045387994143485e-06,
      "loss": 0.596586685180664,
      "step": 4900
    },
    {
      "epoch": 1.830161054172767,
      "grad_norm": 9.269491195678711,
      "learning_rate": 7.801366520253782e-06,
      "loss": 0.5835841751098633,
      "step": 5000
    },
    {
      "epoch": 1.8667642752562226,
      "grad_norm": 18.5439395904541,
      "learning_rate": 7.557345046364081e-06,
      "loss": 0.5986918640136719,
      "step": 5100
    },
    {
      "epoch": 1.903367496339678,
      "grad_norm": 6.728139877319336,
      "learning_rate": 7.313323572474378e-06,
      "loss": 0.5882500839233399,
      "step": 5200
    },
    {
      "epoch": 1.939970717423133,
      "grad_norm": 10.518880844116211,
      "learning_rate": 7.069302098584676e-06,
      "loss": 0.5777288436889648,
      "step": 5300
    },
    {
      "epoch": 1.9765739385065886,
      "grad_norm": 13.216568946838379,
      "learning_rate": 6.825280624694973e-06,
      "loss": 0.594541358947754,
      "step": 5400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.6471449487554904,
      "eval_f1": 0.47778981581798485,
      "eval_loss": 0.6531370282173157,
      "eval_runtime": 112.4659,
      "eval_samples_per_second": 24.292,
      "eval_steps_per_second": 3.041,
      "step": 5464
    },
    {
      "epoch": 2.013177159590044,
      "grad_norm": 24.29946517944336,
      "learning_rate": 6.581259150805271e-06,
      "loss": 0.5677924728393555,
      "step": 5500
    },
    {
      "epoch": 2.049780380673499,
      "grad_norm": 8.89510440826416,
      "learning_rate": 6.337237676915569e-06,
      "loss": 0.5642783737182617,
      "step": 5600
    },
    {
      "epoch": 2.0863836017569546,
      "grad_norm": 5.085953235626221,
      "learning_rate": 6.093216203025867e-06,
      "loss": 0.519361343383789,
      "step": 5700
    },
    {
      "epoch": 2.12298682284041,
      "grad_norm": 6.368710041046143,
      "learning_rate": 5.849194729136164e-06,
      "loss": 0.512600326538086,
      "step": 5800
    },
    {
      "epoch": 2.159590043923865,
      "grad_norm": 5.5450239181518555,
      "learning_rate": 5.605173255246462e-06,
      "loss": 0.560429573059082,
      "step": 5900
    },
    {
      "epoch": 2.1961932650073206,
      "grad_norm": 10.394085884094238,
      "learning_rate": 5.361151781356759e-06,
      "loss": 0.5299172210693359,
      "step": 6000
    },
    {
      "epoch": 2.232796486090776,
      "grad_norm": 10.427353858947754,
      "learning_rate": 5.117130307467058e-06,
      "loss": 0.559973373413086,
      "step": 6100
    },
    {
      "epoch": 2.269399707174231,
      "grad_norm": 8.296502113342285,
      "learning_rate": 4.873108833577356e-06,
      "loss": 0.5265017318725586,
      "step": 6200
    },
    {
      "epoch": 2.3060029282576866,
      "grad_norm": 4.9954633712768555,
      "learning_rate": 4.6290873596876525e-06,
      "loss": 0.48660953521728517,
      "step": 6300
    },
    {
      "epoch": 2.342606149341142,
      "grad_norm": 18.91834831237793,
      "learning_rate": 4.38506588579795e-06,
      "loss": 0.5234994506835937,
      "step": 6400
    },
    {
      "epoch": 2.379209370424597,
      "grad_norm": 17.00542640686035,
      "learning_rate": 4.141044411908248e-06,
      "loss": 0.5315572357177735,
      "step": 6500
    },
    {
      "epoch": 2.4158125915080526,
      "grad_norm": 11.49215030670166,
      "learning_rate": 3.897022938018546e-06,
      "loss": 0.5473396682739258,
      "step": 6600
    },
    {
      "epoch": 2.452415812591508,
      "grad_norm": 6.759352684020996,
      "learning_rate": 3.6530014641288437e-06,
      "loss": 0.5474033355712891,
      "step": 6700
    },
    {
      "epoch": 2.4890190336749636,
      "grad_norm": 19.172021865844727,
      "learning_rate": 3.4089799902391415e-06,
      "loss": 0.5334914398193359,
      "step": 6800
    },
    {
      "epoch": 2.5256222547584186,
      "grad_norm": 12.265891075134277,
      "learning_rate": 3.164958516349439e-06,
      "loss": 0.5157527923583984,
      "step": 6900
    },
    {
      "epoch": 2.562225475841874,
      "grad_norm": 32.406192779541016,
      "learning_rate": 2.9209370424597366e-06,
      "loss": 0.547610092163086,
      "step": 7000
    },
    {
      "epoch": 2.5988286969253296,
      "grad_norm": 12.11731243133545,
      "learning_rate": 2.6769155685700344e-06,
      "loss": 0.5512678527832031,
      "step": 7100
    },
    {
      "epoch": 2.6354319180087846,
      "grad_norm": 13.887768745422363,
      "learning_rate": 2.432894094680332e-06,
      "loss": 0.5331485748291016,
      "step": 7200
    },
    {
      "epoch": 2.67203513909224,
      "grad_norm": 24.109006881713867,
      "learning_rate": 2.1888726207906296e-06,
      "loss": 0.5009437942504883,
      "step": 7300
    },
    {
      "epoch": 2.7086383601756956,
      "grad_norm": 10.114326477050781,
      "learning_rate": 1.9448511469009274e-06,
      "loss": 0.5299631500244141,
      "step": 7400
    },
    {
      "epoch": 2.745241581259151,
      "grad_norm": 27.639768600463867,
      "learning_rate": 1.7008296730112251e-06,
      "loss": 0.5343760681152344,
      "step": 7500
    },
    {
      "epoch": 2.781844802342606,
      "grad_norm": 17.93018341064453,
      "learning_rate": 1.4568081991215227e-06,
      "loss": 0.5159451675415039,
      "step": 7600
    },
    {
      "epoch": 2.8184480234260616,
      "grad_norm": 9.418060302734375,
      "learning_rate": 1.2127867252318205e-06,
      "loss": 0.5514532089233398,
      "step": 7700
    },
    {
      "epoch": 2.855051244509517,
      "grad_norm": 12.507157325744629,
      "learning_rate": 9.687652513421183e-07,
      "loss": 0.5167036437988282,
      "step": 7800
    },
    {
      "epoch": 2.891654465592972,
      "grad_norm": 10.248897552490234,
      "learning_rate": 7.247437774524159e-07,
      "loss": 0.5246639633178711,
      "step": 7900
    },
    {
      "epoch": 2.9282576866764276,
      "grad_norm": 11.89682388305664,
      "learning_rate": 4.807223035627135e-07,
      "loss": 0.48833236694335935,
      "step": 8000
    },
    {
      "epoch": 2.964860907759883,
      "grad_norm": 13.226274490356445,
      "learning_rate": 2.3670082967301126e-07,
      "loss": 0.525875358581543,
      "step": 8100
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.6405563689604685,
      "eval_f1": 0.5785407725321888,
      "eval_loss": 0.6851469874382019,
      "eval_runtime": 112.6775,
      "eval_samples_per_second": 24.246,
      "eval_steps_per_second": 3.035,
      "step": 8196
    }
  ],
  "logging_steps": 100,
  "max_steps": 8196,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.725008701151232e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
